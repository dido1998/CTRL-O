# @package _global_
# Common parameters for DINOSAUR.
defaults:
  - /settings/output_path
  - /settings/epochless
  - /settings/log_frequencies
  - /training_config
  - _self_

experiment:
  image_size: 224
  mask_size: ${.image_size}
  batch_size_per_gpu: 64

  # Empty values to be set in downstream configs
  slot_dim: null
  num_slots: null
  timm_model: null

  # Automatically derived properties
  feature_dim: "${timm_model_dim: ${.timm_model}}"
  num_patches: "${timm_model_num_patches: ${.timm_model}, ${.image_size}}"
  num_patches_per_side: "${isqrt: ${.num_patches}}"
  patch_size: "${timm_model_patch_size: ${.timm_model}}"
  total_batch_size: "${mul: ${trainer.devices}, ${.batch_size_per_gpu}}"
  total_lr: 0.0001

trainer:
  devices: 1
  max_steps: 100000
  gradient_clip_val: 1.0

models:
  feature_extractor:
    _target_: routed.ocl.feature_extractors.TimmFeatureExtractor
    model_name: ${experiment.timm_model}
    pretrained: ${when_testing:false,true}
    freeze: true
    feature_level: 12
    video_path: input.image

  conditioning:
    _target_: null
    n_slots: ${experiment.num_slots}
    object_dim: ${experiment.slot_dim}
    batch_size_path: input.batch_size

  perceptual_grouping:
    _target_: routed.ocl.perceptual_grouping.SlotAttentionGrouping
    feature_dim: ${.object_dim}
    object_dim: ${experiment.slot_dim}
    use_projection_bias: false
    positional_embedding:
      _target_: ocl.neural_networks.wrappers.Sequential
      _args_:
        - _target_: ocl.neural_networks.positional_embedding.DummyPositionEmbed
        - _target_: ocl.neural_networks.build_two_layer_mlp
          input_dim: ${experiment.feature_dim}
          output_dim: ${....feature_dim}
          hidden_dim: "${mul: ${experiment.feature_dim}, 2}"
          initial_layer_norm: true
    ff_mlp:
      _target_: ocl.neural_networks.build_two_layer_mlp
      input_dim: ${..object_dim}
      output_dim: ${..object_dim}
      hidden_dim: "${mul: ${..object_dim}, 4}"
      initial_layer_norm: true
      residual: true
    feature_path: feature_extractor
    conditioning_path: conditioning

  object_decoder:
    _target_: null
    object_dim: ${experiment.slot_dim}
    output_dim: ${experiment.feature_dim}
    num_patches: ${experiment.num_patches}
    object_features_path: perceptual_grouping.objects
    image_path: input.image

  projector_slots:
    _target_: routed.ocl.heads.SlotProjectorHead
    dim: ${experiment.slot_dim}
    embedding_dim: 4096
    slots_path: perceptual_grouping.objects

  dual_embedding:
    _target_: routed.ocl.heads.DualEmbeddingHead
    embedding_dim: 4096
    name_embedding_path: input.name_embedding
    point_embedding_path: input.bbox_centroids

  mask_matching:
    _target_: routed.ocl.matching.MaskMatching
    pred_masks_path: object_decoder.masks_as_image
    true_masks_path: input.instance_mask_v2
    selected_indices_path: input.selected_indices

optimizers:
  opt0:
    _target_: ocl.optimization.OptimizationWrapper
    optimizer:
      _target_: torch.optim.Adam
      _partial_: true
      lr: ${experiment.total_lr}
    lr_scheduler:
      _target_: ocl.scheduling.exponential_decay_after_optional_warmup
      _partial_: true
      decay_rate: 0.5
      decay_steps: 100000
      warmup_steps: 10000

losses:
  reference_loss:
    _target_: routed.ocl.losses.EmbeddingRefereceLoss
    slot_embeddings_path: projector_slots
    ctrl_embeddings_path: dual_embedding
    ctrl_indecies_path: mask_matching.gt_masks_indecies
    slots_indecies_path: mask_matching.slots_indecies

dataset:
  num_workers: 4
  batch_size: ${experiment.batch_size_per_gpu}
