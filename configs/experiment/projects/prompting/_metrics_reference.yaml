# @package _global_
evaluation_metrics:
  instance_mbo:
    _target_: routed.ocl.metrics.UnsupervisedMaskIoUMetric
    prediction_path: object_decoder.masks_as_image
    target_path: input.instance_mask
    use_threshold: false
    matching: best_overlap
    ignore_overlaps: true
  instance_ari:
    _target_: routed.ocl.metrics.ARIMetric
    prediction_path: object_decoder.masks_as_image
    target_path: input.instance_mask_v2
    foreground: false
    convert_target_one_hot: true
    ignore_overlaps: true
  acc_sc:
    _target_: routed.ocl.metrics.acc.EmbAccMetric
    mode: sc
    slot_emb_path: projector_slots
    ctrl_emb_path: dual_embedding
    ctrl_idx_path: mask_matching.gt_masks_indecies
    slots_idx_path: mask_matching.slots_indecies

  acc_cs:
    _target_: routed.ocl.metrics.acc.EmbAccMetric
    mode: cs
    slot_emb_path: projector_slots
    ctrl_emb_path: dual_embedding
    ctrl_idx_path: mask_matching.gt_masks_indecies
    slots_idx_path: mask_matching.slots_indecies

  acc_avg:
    _target_: routed.ocl.metrics.acc.EmbAccMetric
    mode: average
    slot_emb_path: projector_slots
    ctrl_emb_path: dual_embedding
    ctrl_idx_path: mask_matching.gt_masks_indecies
    slots_idx_path: mask_matching.slots_indecies

training_metrics:
  acc_sc:
    _target_: routed.ocl.metrics.acc.EmbAccMetric
    mode: sc
    slot_emb_path: projector_slots
    ctrl_emb_path: dual_embedding
    ctrl_idx_path: mask_matching.gt_masks_indecies
    slots_idx_path: mask_matching.slots_indecies

  acc_cs:
    _target_: routed.ocl.metrics.acc.EmbAccMetric
    mode: cs
    slot_emb_path: projector_slots
    ctrl_emb_path: dual_embedding
    ctrl_idx_path: mask_matching.gt_masks_indecies
    slots_idx_path: mask_matching.slots_indecies

  acc_avg:
    _target_: routed.ocl.metrics.acc.EmbAccMetric
    mode: average
    slot_emb_path: projector_slots
    ctrl_emb_path: dual_embedding
    ctrl_idx_path: mask_matching.gt_masks_indecies
    slots_idx_path: mask_matching.slots_indecies

visualizations:
  input:
    _target_: routed.ocl.visualizations.Image
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
  masks:
    _target_: routed.ocl.visualizations.Mask
    mask_path: object_decoder.masks_as_image

  gt_masks_matched:
    _target_: routed.ocl.visualizations.Segmentation
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
    mask_path: mask_matching.matched_gt_masks

  pred_masks_matched:
    _target_: routed.ocl.visualizations.Segmentation
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
    mask_path: mask_matching.matched_pred_masks

  gt_masks:
    _target_: routed.ocl.visualizations.Segmentation
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
    mask_path: input.instance_mask_v2


  pred_segmentation:
    _target_: routed.ocl.visualizations.Segmentation
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
    mask_path: object_decoder.masks_as_image
