# @package _global_
# Common parameters for DINOSAUR.
defaults:
  - /settings/output_path
  - /settings/epochless
  - /settings/log_frequencies
  - /training_config
  - _self_

experiment:
  image_size: 224
  mask_size: ${.image_size}
  batch_size_per_gpu: 64
  base_learning_rate: 0.0004
  max_num_binds: 7

  # Empty values to be set in downstream configs
  slot_dim: null
  num_slots: null
  timm_model: null

  # Automatically derived properties
  feature_dim: "${timm_model_dim: ${.timm_model}}"
  num_patches: "${timm_model_num_patches: ${.timm_model}, ${.image_size}}"
  num_patches_per_side: "${isqrt: ${.num_patches}}"
  patch_size: "${timm_model_patch_size: ${.timm_model}}"
  total_batch_size: "${mul: ${trainer.devices}, ${.batch_size_per_gpu}}"
  total_lr: "${eval: 'a * (b / 64)**0.5', ${.base_learning_rate}, ${.total_batch_size}}"

trainer:
  devices: 1
  max_steps: 150000
  gradient_clip_val: 1.0

models:
  feature_extractor:
    _target_: routed.ocl.feature_extractors.TimmFeatureExtractor
    model_name: ${experiment.timm_model}
    pretrained: ${when_testing:false,true}
    freeze: true
    feature_level: 12
    video_path: input.image

  conditioning:
    _target_: null
    n_slots: ${experiment.num_slots}
    object_dim: ${experiment.slot_dim}
    batch_size_path: input.batch_size

  perceptual_grouping:
    _target_: routed.ocl.perceptual_grouping.SlotAttentionGrouping
    feature_dim: ${.object_dim}
    object_dim: ${experiment.slot_dim}
    use_projection_bias: false
    positional_embedding:
      _target_: ocl.neural_networks.wrappers.Sequential
      _args_:
        - _target_: ocl.neural_networks.positional_embedding.DummyPositionEmbed
        - _target_: ocl.neural_networks.build_two_layer_mlp
          input_dim: ${experiment.feature_dim}
          output_dim: ${....feature_dim}
          hidden_dim: "${mul: ${experiment.feature_dim}, 2}"
          initial_layer_norm: true
    ff_mlp:
      _target_: ocl.neural_networks.build_two_layer_mlp
      input_dim: ${..object_dim}
      output_dim: ${..object_dim}
      hidden_dim: "${mul: ${..object_dim}, 4}"
      initial_layer_norm: true
      residual: true
    feature_path: feature_extractor
    conditioning_path: conditioning

  object_decoder:
    _target_: null
    object_dim: ${experiment.slot_dim}
    output_dim: ${experiment.feature_dim}
    num_patches: ${experiment.num_patches}
    object_features_path: perceptual_grouping.objects
    image_path: input.image

optimizers:
  opt0:
    _target_: ocl.optimization.OptimizationWrapper
    optimizer:
      _target_: torch.optim.Adam
      _partial_: true
      lr: ${experiment.total_lr}
    lr_scheduler:
      _target_: ocl.scheduling.exponential_decay_after_optional_warmup
      _partial_: true
      decay_rate: 0.5
      decay_steps: 100000
      warmup_steps: 10000

losses:
  mse:
    _target_: routed.ocl.losses.ReconstructionLoss
    loss_type: mse
    input_path: object_decoder.reconstruction
    target_path: feature_extractor.features

dataset:
  num_workers: 4
  batch_size: ${experiment.batch_size_per_gpu}

visualizations:
  input:
    _target_: routed.ocl.visualizations.Image
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
  masks:
    _target_: routed.ocl.visualizations.Mask
    mask_path: object_decoder.masks_as_image
  pred_segmentation:
    _target_: routed.ocl.visualizations.Segmentation
    denormalization:
      _target_: ocl.preprocessing.Denormalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
    image_path: input.image
    mask_path: object_decoder.masks_as_image
