# @package _global_
# Add masking to ViT feature extractor, use unmasked target feature extractor.
defaults:
  - /experiment/projects/scaling/dual_controllable_coco_small14_dinov2
  - /experiment/projects/scaling/mapping/identity_mapping
  - /experiment/projects/scaling/mask_loss/_gt_mask_loss
  - /experiment/projects/scaling/_opt/dual_conditioning/dual
  - _self_

models:
  perceptual_grouping:
      _target_: routed.ocl.perceptual_grouping.ControllableSlotAttentionGrouping
      feature_dim: ${.object_dim}
      object_dim: ${experiment.slot_dim}
      use_projection_bias: false
      positional_embedding:
        _target_: ocl.neural_networks.wrappers.Sequential
        _args_:
          - _target_: ocl.neural_networks.positional_embedding.DummyPositionEmbed
          - _target_: ocl.neural_networks.build_two_layer_mlp
            input_dim: ${experiment.feature_dim}
            output_dim: ${....feature_dim}
            hidden_dim: "${mul: ${experiment.feature_dim}, 2}"
            initial_layer_norm: true
      ff_mlp:
        _target_: ocl.neural_networks.build_two_layer_mlp
        input_dim: ${..object_dim}
        output_dim: ${..object_dim}
        hidden_dim: "${mul: ${..object_dim}, 4}"
        initial_layer_norm: true
        residual: true
      dual_conditioning: false
      feature_path: mapping
      conditioning_path: conditioning
      dual_conditioning_path: dual_conditioning
